인공지능의 정의
- 'Acting Rationally'에 초점

일반적인 Agent
1. Perceive(input, by sensors)
2. Think(process, deliberation)
3. Act(by actuators)
- able to think & react with the environment

Learning Agent
- 다른 agent보다 더 complex

인공지능의 역사 (review)
- 제1차 붐(1956 ~ 1970): 기호 처리 분야
- 제2차 붐(1980 ~ 1995): 전문가 시스템
- 제3차 붐(2010 ~ 현재): 학습

지능에는 뇌와 신체가 모두 중요
- 심볼 그라운딩 문제: 하드웨어가 없다면 인공지능은 표상을 실제 세계에 결부시켜 이해할 수 없다는 문제

알파고
- 알파고는 딥러닝과 **탐색 기법**을 통하여 다음 수를 읽었다.

탐색
- 상태공간에서 초기상태부터 목표상태까지의 경로를 찾는 것
- 상태공간: 상태들이 모여 있는 공간
- 연산자: 다음 상태를 생성하는 것

기본적인 탐색 기법
- 정보 없는 검색 전략(맹목적인 탐색): DFS, BFS, 균일 비용 탐색
- 정보 있는 검색 전략(경험적인 탐색): 탐욕적인 탐색, A* 탐색

깊이 우선 탐색 (DFS)
- 탐색 트리 상에서, 자식 노드가 있다면 아래로 계속 전진하여 탐색하는 방법

OPEN, CLOSED 리스트
- 탐색에서는 **중복된 상태를 막기 위하여** 2개의 리스트를 사용
- OPEN 리스트: 확장은 되었으나 아직 탐색하지 않은 상태들이 들어있는 리스트
- CLOSED 리스트: 탐색이 끝난 상태들이 들어있는 리스트

DFS 알고리즘
```
depth_first_search()

open <- [시작노드]
closed <- [ ]
while open != [ ] do
    X <- open 리스트의 첫 번째 요소
    if X == goal then return SUCCESS
    else
        X의 자식 노드를 생성
        X를 closed 리스트에 추가
        X의 자식 노드가 이미 open이나 closed에 있다면 버림
        X의 남은 자식 노드들을 open의 처음에 추가 (스택처럼 사용)
return FAIL
```

너비 우선 탐색 (BFS)
- 루트 노드의 모든 자식 노드들을 너비로 탐색한 후에 해가 발견되지 않으면 한 레벨 내려가서 동일한 방법으로 탐색을 계속하는 방법

BFS 알고리즘
```
breadth_first_search()

open <- [시작노드]
closed <- [ ]
while open != [ ] do
    X <- open 리스트의 첫 번째 요소
    if X == goal then return SUCCESS
    else
        X의 자식 노드를 생성
        X를 closed 리스트에 추가
        X의 자식 노드가 이미 open이나 closed에 있다면 버림
        X의 남은 자식 노드들을 open의 끝에 추가 (큐처럼 사용)
return FAIL
```

경험적인 탐색 방법
- 문제 영역에 대한 정보나 지식 사용
- 경험적 탐색 방법 또는 휴리스틱 탐색 방법이라고 칭함
- 이때 사용되는 정보를 휴리스틱 정보라고 함

A* 탐색
- 출발 지점으로부터 특정 지점까지의 거리와 특정 지점으로부터 목적지까지의 추정 거리의 합계가 작은 순서대로 탐색 진행
- 추정값을 실제 거리보다 **작게** 잡아 탐색: 낙관적, 허용적 추정

Asymmetric case: 비터비 알고리즘
- 각 시간의 탐색 순서 등을 전혀 신경 쓰지 않고 어떤 시간의 A, B, C, ... 각 지점으로부터 다음 시간의 A, B, C, ... 각 지점까지의 비용을 모두 구해서 **가장 비용이 낮은** A, B, C, ...을 남기는 과정 반복

8-puzzle
```python
# 상태를 나타내는 클래스
class State:
    def __init__(self, board, goal, moves=0):
        self.board = board
        self.moves = moves
        self.goal = goal

    # i1과 i2를 교환하여서 새로운 상태를 반환한다.
    def get_new_board(self, i1, i2, moves):
        new_board = self.board[:]
        new_board[i1], new_board[i2] = new_board[i2], new_board[i1]
        return State(new_board, self.goal, moves)
    
    # 자식 노드를 확장하여서 리스트에 저장하여서 반환한다.
    def expand(self, moves):
        result = []
        i = self.board.index(0) # 숫자 0(빈칸)의 위치를 찾는다.
        if not i in [0, 1, 2]: # UP 연산자
            result.append(self.get_new_board(i, i-3, moves))
        if not i in [0, 3, 6]: # LEFT 연산자
            result.append(self.get_new_board(i, i-1, moves))
        if not i in [2, 5, 8]: # RIGHT 연산자
            result.append(self.get_new_board(i, i+1, moves))
        if not i in [6, 7, 8]: # DOWN 연산자
            result.append(self.get_new_board(i, i+3, moves))

        print("Final result\n", result.pop(0))
        return result
    
    # 객체를 출력할 때 사용한다.
    def __str__(self):
        return str(self.board[:3]) + "\n" + str(self.board[3:6]) + "\n" + str(self.board[6:]) + "\n"
    

# 초기 상태
puzzle = [1, 2, 3, 
          0, 4, 6,
          7, 5, 8]

# 목표 상태
goal = [1, 2, 3, 
        4, 5, 6,
        7, 8, 0]

# open 리스트
open_queue = []
open_queue.append(State(puzzle, goal))

closed_queue = []
moves = 0
while len(open_queue) != 0:
    # OPEN 리스트의 앞에서 삭제
    current = open_queue.pop(0)
    # print(current)
    if current.board == goal:
        print("탐색 성공")
        break
    moves = current.moves + 1
    print("# of moves:", moves)
    closed_queue.append(current)
    for state in current.expand(moves):
        # 이미 거쳐간 노드이면
        if state in closed_queue or state in open_queue:
            continue # 노드를 버린다.
        else:
            open_queue.append(state) # OPEN 리스트의 끝에 추가
```

AI 응용 별 적용 가능한 탐색 기법
| 인공지능 기초 응용 예시           | DFS | BFS | 균일비용 | 탐욕탐색 | A* | Viterbi | ... |
|---------------------------------|-----|-----|----------|----------|----|---------|-----|
| 차량용 네비게이션                 | ⭕  | ⭕  | ⭕       | ⭕       | ⭕ |         |     |
| 8-puzzle                        | ⭕  | ⭕  | ??       | ??       | ⭕ | ??      |     |
| 일반문제_강 건너기               |     |     |          |          |    |         |     |
| 틱택토 게임                      |     |     |          |          |    |         |     |
| ..                              |     |     |          |          |    |         |     |
| ..                              |     |     |          |          |    |         |     |

언덕 등반 기법
- 무조건 휴리스틱 함수 값이 가장 좋은 노드만을 선택

언덕 등산 기법 알고리즘
1. 먼저 현재 위치를 기준으로 해서, 각 방향의 높이를 판단 (노드의 확장)
2. 만일 모든 위치가 현 위치보다 낮다면 그곳을 정상이라고 판단 (목표상태인가의 검사)
3. 현 위치가 정상이 아니라면 확인된 위치 중 가장 높은 곳으로 이동 (후계노드의 선택)

지역 최소 문제
- 순수한 언덕 등반 기법은 오직 h(n) 값만을 사용
- OPEN, CLOSED 리스트 사용 X
- 이런 경우에는 생성된 자식 노드의 평가 함수 값이 부모 노드보다 더 높거나 같은 경우가 나올 수 있음. 이것을 지역 최소 문제라고 함.

A* 알고리즘
- 평가 함수의 값 f(n) = g(n) + h(n)
- g(n): 시작 노드에서 현재 노드까지의 비용
- h(n): 현재 노드에서 목표 노드까지의 거리
- 8-puzzle에서 h(n)은 제 위치에 있지 않은 타일의 개수
```
AStar_search()

open <- [시작노드]
closed <- [ ]
while open != [ ] do
    X <- open 리스트에서 가장 평가 함수 값이 좋은 노드
    if X == goal then return SUCCESS
    else
        X의 자식 노드를 생성
        X를 closed 리스트에 추가
        if X의 자식 노드가 open이나 closed에 있지 않으면
            자식 노드의 평가 함수 값 f(n) = g(n) + h(n) 계산
            자식 노드들을 open에 추가
return FAIL
```

A* 알고리즘 파이썬 구현
```python
import queue

# 상태를 나타내는 클래스, f(n) 값을 저장한다.
class State:
    def __init__(self, board, goal, moves=0):
        self.board = board
        self.moves = moves
        self.goal = goal

    # i1과 i2를 교환하여서 새로운 상태를 반환한다.
    def get_new_board(self, i1, i2, moves):
        new_board = self.board[:]
        new_board[i1], new_board[i2] = new_board[i2], new_board[i1]
        return State(new_board, self.goal, moves)
    
    # 자식 노드를 확장하여서 리스트에 저장하여서 반환한다.
    def expand(self, moves):
        result = []
        i = self.board.index(0)
        if not i in [0, 1, 2]:
            result.append(self.get_new_board(i, i-3, moves))
        if not i in [0, 3, 6]:
            result.append(self.get_new_board(i, i-1, moves))
        if not i in [2, 5, 8]:
            result.append(self.get_new_board(i, i+1, moves))
        if not i in [6, 7, 8]:
            result.append(self.get_new_board(i, i+3, moves))
        return result
    
    # f(n)을 계산하여 반환한다.
    def f(self):
        return self.h() + self.g()
    
    # 휴리스틱 함수 값인 h(n)을 계산하여 반환한다.
    # 현재 제 위치에 있지 않은 타일의 개수를 리스트 함축으로 계산한다.
    def h(self):
        # return sum([1 if self.board[i] != self.goal[i] else 0 for i in range(8)])
        return sum([1 if self.board[i] != self.goal[i] and self.goal[i] != 0 else 0 for i in range(9)])
    
    # 시작 노드로부터의 경로를 반환한다.
    def g(self):
        return self.moves
    
    # 상태와 상태를 비교하기 위하여 less than 연산자를 정의한다.
    def __lt__(self, other):
        return self.f() < other.f()
    
    # 객체를 출력할 때 사용한다.
    def __str__(self):
        return "------------------ f(n)=" + str(self.f()) +"\n"+\
        "------------------ h(n)=" + str(self.h()) +"\n"+\
        "------------------ g(n)=" + str(self.g()) +"\n"+\
        str(self.board[:3]) +"\n"+\
        str(self.board[3:6]) +"\n"+\
        str(self.board[6:]) +"\n"+\
        "------------------"

# 초기 상태
puzzle = [1, 2, 3, 
          0, 4, 6, 
          7, 5, 8]

# 목표 상태
goal = [1, 2, 3, 
        4, 5, 6,
        7, 8, 0]

# open 리스트는 우선순위 큐로 생성한다.
open_queue = queue.PriorityQueue()
open_queue.put(State(puzzle, goal))

closed_queue = []
moves =0
while not open_queue.empty():
    current = open_queue.get()
    print(current)
    if current.board == goal:
        print("탐색 성공")
        break
    moves = current.moves + 1
    for state in current.expand(moves):
        if state not in closed_queue:
            open_queue.put(state)
        closed_queue.append(current)
else:
    print("탐색 실패")
```

미니맥스 알고리즘
- 상대방의 차례에는 자신에게 있어서 가장 나쁜 것(Min)이 선택되고, 자신의 차례에는 가장 좋은 것(Max)이 선택되는 것
- 상태에 승패를 붙이고, 시스템 입장에서 승리인 상태가 선택지에 있으면 그 상태로 이동하도록 함
- 평가치를 사용해서 거꾸로 계산: 각각의 상태에 승패를 대신할 수치를 설정하여 그곳에서부터 거꾸로 계산
  
알파-베타 가지치기
- 탐색 트리에서 미니맥스 알고리즘을 적용할 떄 평가하는 노드의 수를 줄이기 위한 알고리즘
- 이전에 평가한 노드보다 현재 평가하는 노드가 더 좋지 않을 가능성이 있으면 평가를 중단
- 이 노드의 남은 형제 노드와 모든 후손 노드는 가지치기되어 평가하지 않음
- 이 알고리즘을 일반적인 미니맥스에 적용하면 동일한 결과를 얻게 됨
- 즉, 최종 결정에 영향을 미치지 않는 가지들을 쳐낼 뿐임

Alpha cut
- 최대화에 기여하지 않으리라는 것이 확실한 경우에는 이후 분기를 고려하지 않음
- 최대화에 착안

Beta cut
- 최소화에 기여하지 않으리라는 것이 확실한 경우에는 이후 분기를 고려하지 않음
- 최소화에 착안

요약 정리
- 탐색: 상태 공간에서 시작 상태부터 목표 상태까지의 경로를 찾는 것
- 연산자: 하나의 상태를 다른 상태로 변경
- 맹목적인 탐색: 목표 노드에 대한 정보를 이용하지 않고 기계적인 순서로 노드를 확장하는 방법 (ex. 깊이 우선 탐색, 너비 우선 탐색)
- 탐색에서는 중복된 상태를 막기 위하여 OPEN 리스트와 CLOSED 리스트 사용
- 경험적인 탐색: 목표 노드에 대한 경험적인 정보를 사용하는 방법 (ex. 언덕 등반 기법, A* 탐색)
- A* 알고리즘의 평가 함수: f(n) = g(n) + h(n)
  - h(n): 현재 노드에서 목표 노드까지의 거리
  - g(n): 시작 노드에서 현재 노드까지의 비용