지능의 정의
1. 인간이 사물을 이해하고 학습하는 능력
2. 어떤 문제가 주어졌을 때, 합리적으로 사고하여 문제를 해결하는 능력 

인공지능의 구현
1. Top-down approach: 지식공학(합리주의, 이성주의)
2. Down-top approach: 머신러닝(경험주의)

인공지능
- 인간처럼 **학습하고 추론**하는 프로그램 연구

기계학습
- 인공지능의 한 분야로서 프로그래밍 없이 **스스로 학습**하는 프로그램 연구

딥러닝
- 인공 신경망 등을 사용하여 **빅데이터로부터 학습**하는 프로그램 연구

최근의 인공지능 활약
- 1997년 IBM의 딥블루: 체스 세계 챔피언 카스퍼로프를 상대로 승리
- 2011년 IBM의 왓슨: 퀴즈쇼 "제퍼디"에서 우승
- 2016년 구글 알파고: 이세돌과의 경기에서 4-1로 승리

튜링 테스트
- 영국의 수학자 알란 튜링은 "기계가 생각할 수 있을까?"라는 질문 대신에 **기계와 사람을 구분할 수 없다면 인공지능이 구현되었다고 봐야 한다고 주장**
- 튜링 테스트를 통과했다고 해서 무조건 완성된 인공지능이라고 할 수 없음

중국인 방
- Searle은 소프트웨어가 자신이 이해하지 못한 기호를 단순히 조작하여 튜링 테스트를 통과할 수 있다고 언급했다. 이해하지 못하면, 사람들과 같은 의미에서 "생각"으로 간주될 수 없다는 것이다.

인공지능의 최신 응용분야
- 자동차 업계: 자율 주행 기술
- 광고 업계: 사용자 맞춤 광고
- 챗봇: 가상 어시스턴트(Google Assistant, Amazon Alexa)
- 의료: 환자 데이터, 환자 설문, 유전자 분석, 진단

강인공지능
- 인공지능의 강한 형태
- 자의식이 있음
- 일반적인 영역에서의 문제도 해결하지만, **명령받지 않은 일도 스스로 필요하다면 해결**할 수 있음

약인공지능
- 인공지능의 약한 형태
- 자의식이 없음
- **특정한 영역에서 주어진 문제를 해결**
- ex. 알파고

인공지능의 특징
- 학습: 과거의 패턴들로부터 학습할 수 있는 능력
- 문제 해결: 복잡한 문제를 분석하고 해결할 수 있는 능력
- 빅데이터: 아주 큰 용량의 변환하는 데이터를 처리
- 추론: 주위의 상황으로부터 추론할 수 있는 능력

인공지능의 역사
- 1943: McCulloch와 Pittes가 인공 신경망의 기초 모델을 정립
- 1950: 앨런 튜링이 기계 지능의 테스트 방법으로 튜링 테스트를 소개
- 1956: 다트머스 학술대회에서 '인공지능(AI)'이란 용어 탄생
- 1957: Rosenblatt이 인공 신경망의 초기 형태인 퍼셉트론을 개발, 1969년 민스키의 'Perceptrons'가 발표되면서 개발 중단
- 1980S: Feigenbaum이 인간 전문가의 의사결정을 흉내내는 전문가 시스템 개발
- 1982: 물리학자 Hopfield는 완전히 새로운 방식으로 정보를 학습하고 처리할 수 있는 한 형태의 신경망(Hopfield Net)을 제안
- 1986: Hinton과 Rumelhart는 '역전파(backpropagation)'라고 불리는 유명한 학습 방법을 대중화
- 1997: IBM의 컴퓨터 딥블루가 체스 챔피언을 이김
- 2009: 구글이 자율주행 자동차를 선보임
- 2011: IBM의 컴퓨터 왓슨이 게임쇼에서 인간을 누르고 우승
- 2011 ~ 2014: 시리나 구글 나우 같은 음성인식 개인 비서가 등장
- 2016: 알파고가 이세돌을 이김

인공지능의 발전 흐름
- 1950 ~ 1956: 인공지능의 태동 (1차)
- 1960 ~ 1975: 전문가 시스템과 1차 인공지능 붐, 고조된 기대
  - 다수의 조건 분기를 사용하는 규칙 기반 자동 판전 프로그램 발전
  - 전문가 시스템: 전문가가 실행하는 조건 판단을 프로그램화해 문제를 처리하는 시스템 (ex. DENDRAL, MYCIN)
- 1980: 1차 인공지능 암흑기
  - 1970년대 컴퓨팅 파워 부족 (CPU 속도, 메모리 한계 등)
  - 1980년대의 컴퓨터 연산 성능으로는 사고범위 문제를 해결하기 어렵다는 한계에 도달
  - 빅 데이터 부족
  - 전문가 시스템은 몇 가지 특수한 상황에서만 유용함이 밝혀짐
  - 1980년대 후반, 미국의 Strategic Computing Initiative는 AI에 대한 기금을 잔인하게 삭감
- 1987: 새로운 희망
- 1993: 2차 인공지능 암흑기
- 2000 ~ 2010: 통계 기반 머신러닝(분류, 예측)과 분산 처리 기술의 발전 (2차)
  - 컴퓨팅 연산 성능이 향상된 이유는 1990년대 후반 고속 인터넷망 보급과 함께 대용량 이미지나 동영상 등이 만들어지기 시작했고, 이를 처리하거나 분석할 필요성이 생겼기 때문
  - 그 결과 컴퓨팅 연산 성능을 개선하고, 하드웨어와 소프트웨어 모두를 고려하는 데이터 분산 처리 기술의 발전
  - 무어의 법칙에 따른 하드웨어 성능 향상과 분산 처리 기술이 결합하면서 2000년대 중반부터 다시 신경망 연구가 활발해짐
  - 통계 기반 머신러닝 연구가 활발해진 계기는 1990년대 베이즈 정리를 출발점에 둔 베이즈 통계학의 재조명임
  - 컴퓨팅 연산 성능이 향상된 이유는 1990년대 후반 고속 인터넷망 보급과 함께 대용량 이미지나 동영상 등이 만들어지기 시작했고, 이를 처리하거나 분석할 필요성이 생겼기 때문
- 2010년 이후: 심층 신경망 기반 이미지 인식 성능 향상과 인공지능 붐 (3차)
  - 2000년대 분산 처리 기술과 신경망 연구가 결합하면서 신경망 기반 머신러닝의 이미지 인식의 정확도가 더 좋아지게 됨
  - 음성 인식과 자연어 처리에도 딥러닝을 활용하기 시작
  - 딥러닝은 많은 레이어가 있는 신경 회로망을 사용하여 데이터의 추상화를 모델링하는 기계 학습의 한 분야
- 인공지능의 미래: '의식'을 지닌 인공지능
  - 빅데이터와 디지털 클론
  - 기술적 특이점과 인공지능의 윤리적 관점

특이점
- 인공지능이 인간을 능가하는 순간
- 2045년 경에는 인류의 뇌에서 일어나는 모든 계산량을 컴퓨터로 처리할 수 있게 된다고 함